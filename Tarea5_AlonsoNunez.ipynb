{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea #5\n",
    "## Clase #6\n",
    "### Curso: BigData, Ciencia de los Datos\n",
    "    \n",
    "### Alonso Nu침ez Sanchez\n",
    "### 27 Enero 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro ML SUP en BD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creaci칩n de la sesi칩n Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import SparkSession\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el spark session object, llamarle \"supervised_ml\"\n",
    "spark=SparkSession.builder.appName('supervised_ml').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos, archivo *Linear_regression_dataset.csv*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df=spark.read.csv('Linear_regression_dataset.csv',inferSchema=True,header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se invocan las librerias correcpondientes a **LinearRegression**, asi como las de OneHotEncoder, StringIndexer, VectorAssembler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de libs y operaciones\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se visualizan algunos datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1232, 6)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestran los primeros 10 datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.247</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>748</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>669</td>\n",
       "      <td>588</td>\n",
       "      <td>97</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>667</td>\n",
       "      <td>845</td>\n",
       "      <td>68</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>758</td>\n",
       "      <td>890</td>\n",
       "      <td>64</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>726</td>\n",
       "      <td>670</td>\n",
       "      <td>88</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.268</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_1  var_2  var_3  var_4  var_5  label\n",
       "0    734    688     81  0.328  0.259  0.418\n",
       "1    700    600     94  0.320  0.247  0.389\n",
       "2    712    705     93  0.311  0.247  0.417\n",
       "3    734    806     69  0.315  0.260  0.415\n",
       "4    613    759     61  0.302  0.240  0.378\n",
       "5    748    676     85  0.318  0.255  0.422\n",
       "6    669    588     97  0.315  0.251  0.411\n",
       "7    667    845     68  0.324  0.251  0.381\n",
       "8    758    890     64  0.330  0.274  0.436\n",
       "9    726    670     88  0.335  0.268  0.422"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# primeros 10 datos\n",
    "df.limit(10).toPandas().head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un solo vector con todos los features i.e 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', a este le llamaremos \"features\" y como salida colocamos a 'label':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Ensamblador\n",
    "\n",
    "df_assembler = VectorAssembler(inputCols=['var_1', 'var_2', 'var_3', 'var_4', 'var_5'], outputCol=\"features\")\n",
    "df = df_assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|features                      |label|\n",
      "+------------------------------+-----+\n",
      "|[734.0,688.0,81.0,0.328,0.259]|0.418|\n",
      "|[700.0,600.0,94.0,0.32,0.247] |0.389|\n",
      "|[712.0,705.0,93.0,0.311,0.247]|0.417|\n",
      "|[734.0,806.0,69.0,0.315,0.26] |0.415|\n",
      "|[613.0,759.0,61.0,0.302,0.24] |0.378|\n",
      "|[748.0,676.0,85.0,0.318,0.255]|0.422|\n",
      "|[669.0,588.0,97.0,0.315,0.251]|0.411|\n",
      "|[667.0,845.0,68.0,0.324,0.251]|0.381|\n",
      "|[758.0,890.0,64.0,0.33,0.274] |0.436|\n",
      "|[726.0,670.0,88.0,0.335,0.268]|0.422|\n",
      "|[583.0,794.0,55.0,0.302,0.236]|0.371|\n",
      "|[676.0,746.0,72.0,0.317,0.265]|0.4  |\n",
      "|[767.0,699.0,89.0,0.332,0.274]|0.433|\n",
      "|[637.0,597.0,86.0,0.317,0.252]|0.374|\n",
      "|[609.0,724.0,69.0,0.308,0.244]|0.382|\n",
      "|[776.0,733.0,83.0,0.325,0.259]|0.437|\n",
      "|[701.0,832.0,66.0,0.325,0.26] |0.39 |\n",
      "|[650.0,709.0,74.0,0.316,0.249]|0.386|\n",
      "|[804.0,668.0,95.0,0.337,0.265]|0.453|\n",
      "|[713.0,614.0,94.0,0.31,0.238] |0.404|\n",
      "+------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion de vector ensamblado compuesto por features y label\n",
    "df.select(['features','label']).show(20,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos a continuaci칩n el set de datos en 75% training y 25% testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train Dataset : 896\n",
      "Size of test Dataset : 336\n"
     ]
    }
   ],
   "source": [
    "# Particion del data set\n",
    "model_df=df.select(['features','label'])\n",
    "train,test = model_df.randomSplit([0.75,0.25])\n",
    "\n",
    "print(f\"Size of train Dataset : {train.count()}\" )\n",
    "print(f\"Size of test Dataset : {test.count()}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor Lineal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de regresi칩n lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model, le llamamos lr_model\n",
    "lr_model=lr.fit(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataframe de prediciones (*predictions_df*) a partir del modelo de entrenamiento y el conjunto de datos test: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos el contenido de *predictions_df*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|0.445|    1|\n",
      "|0.319|    1|\n",
      "|0.413|    2|\n",
      "|0.343|    1|\n",
      "|0.394|    3|\n",
      "|0.396|    2|\n",
      "|0.373|    3|\n",
      "|0.369|    2|\n",
      "|0.317|    1|\n",
      "|0.423|    2|\n",
      "|0.329|    2|\n",
      "|0.318|    1|\n",
      "|0.399|    2|\n",
      "|0.352|    4|\n",
      "|0.416|    2|\n",
      "|0.401|    5|\n",
      "|0.415|    4|\n",
      "|0.327|    1|\n",
      "|0.392|    1|\n",
      "|0.419|    3|\n",
      "+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visulizacion de predictions_df\n",
    "predictions_df.groupBy('label').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, evaluamos el modelo de Regresi칩n Lineal, con los datos de TEST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluacion del modelo, le llamaremos model_predictions\n",
    "model_predictions = lr_model.evaluate(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el valor de R2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.867061\n"
     ]
    }
   ],
   "source": [
    "# valor de R2\n",
    "trainingSummary = lr_model.summary\n",
    "\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos el valor del meanSquaredError:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.011987\n"
     ]
    }
   ],
   "source": [
    "# valor del meanSquaredError\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0003336210820382659,6.158717053157263e-05,0.00023087339062401296,-0.6568906388796751,0.4980785935860538]\n",
      "Intercept: 0.18137334024137847\n"
     ]
    }
   ],
   "source": [
    "# otras m칠tricas:\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "\n",
    "print(\"Coefficients: %s\" % str(lr_model.coefficients))\n",
    "print(\"Intercept: %s\" % str(lr_model.intercept))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi칩n con 츼rboles de Decisi칩n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos la librer칤a *DecisionTreeRegressor*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor DT, le llamaremos *dec_tree*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_tree\n",
    "dec_tree = DecisionTreeRegressor(featuresCol=\"features\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos dec_tree_model\n",
    "dec_tree_model = dec_tree.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cu치nto es la profundidad m치xima por defecto, de este algoritmo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta:\n",
    "el par치metro max_depth por defecto est치 configurado en 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las *featureImportances*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,[0,1,2,3,4],[0.9642661892532784,0.017493134111902627,0.0019448235832598278,0.0024390255051261146,0.013856827546432877])\n"
     ]
    }
   ],
   "source": [
    "print(dec_tree_model.featureImportances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions, le llamaremos model_predictions \n",
    "model_predictions = dec_tree_model.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[468.0,746.0,52.0...|0.329| 0.3273333333333334|\n",
      "|[486.0,610.0,61.0...|0.332|0.31800000000000006|\n",
      "|[510.0,588.0,72.0...|0.317|0.31800000000000006|\n",
      "|[511.0,576.0,76.0...|0.329|0.31800000000000006|\n",
      "|[528.0,652.0,71.0...|0.319| 0.3273333333333334|\n",
      "|[543.0,615.0,76.0...|0.333|0.31800000000000006|\n",
      "|[543.0,747.0,60.0...|0.342|              0.355|\n",
      "|[544.0,551.0,82.0...|0.344|0.33955555555555555|\n",
      "|[550.0,631.0,76.0...|0.318|0.33955555555555555|\n",
      "|[558.0,688.0,67.0...| 0.35|0.34913636363636363|\n",
      "|[567.0,587.0,84.0...|0.349|0.34913636363636363|\n",
      "|[568.0,708.0,57.0...|0.347|0.34913636363636363|\n",
      "|[569.0,620.0,77.0...|0.349|0.34913636363636363|\n",
      "|[569.0,711.0,65.0...| 0.34|0.34913636363636363|\n",
      "|[573.0,656.0,75.0...|0.345|0.34913636363636363|\n",
      "|[574.0,586.0,81.0...| 0.36|0.34913636363636363|\n",
      "|[576.0,759.0,57.0...| 0.35|             0.3788|\n",
      "|[578.0,633.0,76.0...|0.337|0.34913636363636363|\n",
      "|[579.0,497.0,91.0...|0.352|0.34913636363636363|\n",
      "|[579.0,655.0,71.0...|0.357|0.34913636363636363|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# visualizamos\n",
    "\n",
    "model_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos el **RegressionEvaluator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Evaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando *RegressionEvaluator* calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-square value of DecisionTreeRegressor is 0.8410597140380105\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0136459\n"
     ]
    }
   ],
   "source": [
    "# R2 value of the model on test data \n",
    "dt_evaluator = RegressionEvaluator(metricName='r2')\n",
    "dt_r2 = dt_evaluator.evaluate(model_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {dt_r2}')\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "dt_evaluator_rmse = RegressionEvaluator(metricName='rmse')\n",
    "rmse = dt_evaluator_rmse.evaluate(model_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a *RandomForestRegressor*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lib\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresor \n",
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos rf_model\n",
    "rf_model = rf.fit(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las *featureImportances*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,[0,1,2,3,4],[0.49362086906566977,0.056194941602342986,0.03261255186079704,0.1916095114420692,0.225962126029121])\n"
     ]
    }
   ],
   "source": [
    "# importances \n",
    "print(rf_model.featureImportances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos el numero de arboles (Num of Trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor_14d21afb5367__numTrees\n"
     ]
    }
   ],
   "source": [
    "# Numero de Trees\n",
    "print(rf_model.numTrees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento, le llamaremos model_predictions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_predictions\n",
    "\n",
    "model_predictions = rf_model.transform(test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos los valores del *model_predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[468.0,746.0,52.0...|0.329| 0.3320035441070367|\n",
      "|[486.0,610.0,61.0...|0.332| 0.3215623970158238|\n",
      "|[510.0,588.0,72.0...|0.317| 0.3256053027650454|\n",
      "|[511.0,576.0,76.0...|0.329|0.32208239701582386|\n",
      "|[528.0,652.0,71.0...|0.319| 0.3327546912931839|\n",
      "|[543.0,615.0,76.0...|0.333|0.32208239701582386|\n",
      "|[543.0,747.0,60.0...|0.342|0.34786874646684013|\n",
      "|[544.0,551.0,82.0...|0.344| 0.3455973167217622|\n",
      "|[550.0,631.0,76.0...|0.318|0.34379262760369067|\n",
      "|[558.0,688.0,67.0...| 0.35|  0.347142071999506|\n",
      "|[567.0,587.0,84.0...|0.349|0.35544802373132517|\n",
      "|[568.0,708.0,57.0...|0.347|0.36023419965808945|\n",
      "|[569.0,620.0,77.0...|0.349| 0.3547970467789357|\n",
      "|[569.0,711.0,65.0...| 0.34|0.35137002135648226|\n",
      "|[573.0,656.0,75.0...|0.345|0.35107295876010214|\n",
      "|[574.0,586.0,81.0...| 0.36|  0.351410791588468|\n",
      "|[576.0,759.0,57.0...| 0.35|0.36932882837059555|\n",
      "|[578.0,633.0,76.0...|0.337|0.35803231620249465|\n",
      "|[579.0,497.0,91.0...|0.352| 0.3465640532754564|\n",
      "|[579.0,655.0,71.0...|0.357|0.35458821444110333|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando *RegressionEvaluator* calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r-square value of DecisionTreeRegressor is 0.845264599879449\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0134641\n"
     ]
    }
   ],
   "source": [
    "# R2 value of the model on test data \n",
    "rf_evaluator = RegressionEvaluator(metricName='r2')\n",
    "rf_r2 = rf_evaluator.evaluate(model_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {rf_r2}')\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "rf_evaluator_rmse = RegressionEvaluator(metricName='rmse')\n",
    "rf_rmse = rf_evaluator_rmse.evaluate(model_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rf_rmse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-Boosted Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos a GBTRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el Regresor GBTR, le llamaremos gbt:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regresor\n",
    "gbtr = GBTRegressor(featuresCol=\"features\", maxIter=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model, le llamaremos gbt_model\n",
    "\n",
    "gbt_model = gbtr.fit(train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos las featureImportances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,[0,1,2,3,4],[0.3121458420400407,0.15735378280936319,0.12342456328662985,0.2061824671760019,0.2008933446879644])\n"
     ]
    }
   ],
   "source": [
    "#Importances\n",
    "print(gbt_model.featureImportances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos el modelo con los datos de entrenamiento, le llamaremos model_predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "model_predictions = gbt_model.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desplegamos los valores del *model_predictions*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+\n",
      "|            features|label|         prediction|\n",
      "+--------------------+-----+-------------------+\n",
      "|[468.0,746.0,52.0...|0.329|0.32675530727704505|\n",
      "|[486.0,610.0,61.0...|0.332|0.31745622324052286|\n",
      "|[510.0,588.0,72.0...|0.317|0.31838257488043564|\n",
      "|[511.0,576.0,76.0...|0.329|0.31905434876653294|\n",
      "|[528.0,652.0,71.0...|0.319|0.32885231982405133|\n",
      "|[543.0,615.0,76.0...|0.333| 0.3195021143949359|\n",
      "|[543.0,747.0,60.0...|0.342|0.35427049155523865|\n",
      "|[544.0,551.0,82.0...|0.344| 0.3394122839935331|\n",
      "|[550.0,631.0,76.0...|0.318| 0.3410576699504914|\n",
      "|[558.0,688.0,67.0...| 0.35| 0.3495156071390776|\n",
      "|[567.0,587.0,84.0...|0.349| 0.3506384780312995|\n",
      "|[568.0,708.0,57.0...|0.347| 0.3492884808051989|\n",
      "|[569.0,620.0,77.0...|0.349|0.35159528648389565|\n",
      "|[569.0,711.0,65.0...| 0.34| 0.3484068551916023|\n",
      "|[573.0,656.0,75.0...|0.345| 0.3450754884534634|\n",
      "|[574.0,586.0,81.0...| 0.36| 0.3506384780312995|\n",
      "|[576.0,759.0,57.0...| 0.35| 0.3789521171688353|\n",
      "|[578.0,633.0,76.0...|0.337|0.35159528648389565|\n",
      "|[579.0,497.0,91.0...|0.352| 0.3428874826295908|\n",
      "|[579.0,655.0,71.0...|0.357|0.34791558791855737|\n",
      "+--------------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show \n",
    "model_predictions.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando RegressionEvaluator calculamos e imprimimos el valor de las metricas R2 y RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+--------------------+\n",
      "|         prediction|label|            features|\n",
      "+-------------------+-----+--------------------+\n",
      "|0.32675530727704505|0.329|[468.0,746.0,52.0...|\n",
      "|0.31745622324052286|0.332|[486.0,610.0,61.0...|\n",
      "|0.31838257488043564|0.317|[510.0,588.0,72.0...|\n",
      "|0.31905434876653294|0.329|[511.0,576.0,76.0...|\n",
      "|0.32885231982405133|0.319|[528.0,652.0,71.0...|\n",
      "+-------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "The r-square value of DecisionTreeRegressor is 0.8455633775802\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0134511\n"
     ]
    }
   ],
   "source": [
    " #Select (prediction, true label) and compute test error\n",
    "    \n",
    "model_predictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# R2 value of the model on test data \n",
    "gbt_evaluator = RegressionEvaluator(metricName='r2')\n",
    "gbt_r2 = gbt_evaluator.evaluate(model_predictions)\n",
    "print(f'The r-square value of DecisionTreeRegressor is {gbt_r2}')\n",
    "\n",
    "# RMSE value of the model on test data \n",
    "gbt_evaluator_rmse = RegressionEvaluator(metricName='rmse')\n",
    "gbt_rmse = gbt_evaluator_rmse.evaluate(model_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % gbt_rmse)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploracion de datos..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset https://archive.ics.uci.edu/ml/datasets/Bank+Marketing \n",
    "\n",
    "Indique a grandes razgos de que se trata este dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuesta:\n",
    "Aparentemente son datos de clientes de un banco para clasificarlos como elegibles o no para una campa침a de marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de datos, archivo bank_data.csv:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Dataset \n",
    "df=spark.read.csv('bank_data.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine la cantidad de datos en el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41188"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of records\n",
    "\n",
    "df.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A que dato corresponde cada columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'job',\n",
       " 'marital',\n",
       " 'education',\n",
       " 'default',\n",
       " 'housing',\n",
       " 'loan',\n",
       " 'contact',\n",
       " 'month',\n",
       " 'day_of_week',\n",
       " 'duration',\n",
       " 'campaign',\n",
       " 'pdays',\n",
       " 'previous',\n",
       " 'poutcome',\n",
       " 'emp.var.rate',\n",
       " 'cons.price.idx',\n",
       " 'cons.conf.idx',\n",
       " 'euribor3m',\n",
       " 'nr.employed',\n",
       " 'target_class']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# columns values\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima el Schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp.var.rate: double (nullable = true)\n",
      " |-- cons.price.idx: double (nullable = true)\n",
      " |-- cons.conf.idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr.employed: double (nullable = true)\n",
      " |-- target_class: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataype of input data - Schema\n",
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la salida, como es la distrubuci칩n de clases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|target_class|count|\n",
      "+------------+-----+\n",
      "|          no|36548|\n",
      "|         yes| 4640|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YES/NO Class Distribution\n",
    "\n",
    "df.groupBy('target_class').count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una tarea t칤pica, resulta de convertir los valores binarios en 1 y 0, usando como referencia \"label\", convierta los no/yes en 0/1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingrese ac치 la instrucci칩n: \n",
    "\n",
    "\n",
    "df = df.withColumn(\"target_class\", F.when(F.col(\"target_class\")=='no', 0).otherwise(1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|target_class|count|\n",
      "+------------+-----+\n",
      "|           1| 4640|\n",
      "|           0|36548|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New 1/0 Class Distribution\n",
    "\n",
    "df.groupBy('target_class').count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci칩n se presenta un ejercicio de Deep Learning para su revisi칩n..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las librerias necesarias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.functions import udf, StringType\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import OneHotEncoder, VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos la sesion SPARK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('deep_learning').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leemos el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('dl_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Visit_Number_Bucket: string (nullable = true)\n",
      " |-- Page_Views_Normalized: double (nullable = true)\n",
      " |-- Orders_Normalized: integer (nullable = true)\n",
      " |-- Internal_Search_Successful_Normalized: double (nullable = true)\n",
      " |-- Internal_Search_Null_Normalized: double (nullable = true)\n",
      " |-- Email_Signup_Normalized: double (nullable = true)\n",
      " |-- Total_Seconds_Spent_Normalized: double (nullable = true)\n",
      " |-- Store_Locator_Search_Normalized: double (nullable = true)\n",
      " |-- Mapped_Last_Touch_Channel: string (nullable = true)\n",
      " |-- Mapped_Mobile_Device_Type: string (nullable = true)\n",
      " |-- Mapped_Browser_Type: string (nullable = true)\n",
      " |-- Mapped_Entry_Pages: string (nullable = true)\n",
      " |-- Mapped_Site_Section: string (nullable = true)\n",
      " |-- Mapped_Promo_Code: string (nullable = true)\n",
      " |-- Maped_Product_Name: string (nullable = true)\n",
      " |-- Mapped_Search_Term: string (nullable = true)\n",
      " |-- Mapped_Product_Collection: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos la columna TARGET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumnRenamed('Orders_Normalized', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Visit_Number_Bucket: string (nullable = true)\n",
      " |-- Page_Views_Normalized: double (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Internal_Search_Successful_Normalized: double (nullable = true)\n",
      " |-- Internal_Search_Null_Normalized: double (nullable = true)\n",
      " |-- Email_Signup_Normalized: double (nullable = true)\n",
      " |-- Total_Seconds_Spent_Normalized: double (nullable = true)\n",
      " |-- Store_Locator_Search_Normalized: double (nullable = true)\n",
      " |-- Mapped_Last_Touch_Channel: string (nullable = true)\n",
      " |-- Mapped_Mobile_Device_Type: string (nullable = true)\n",
      " |-- Mapped_Browser_Type: string (nullable = true)\n",
      " |-- Mapped_Entry_Pages: string (nullable = true)\n",
      " |-- Mapped_Site_Section: string (nullable = true)\n",
      " |-- Mapped_Promo_Code: string (nullable = true)\n",
      " |-- Maped_Product_Name: string (nullable = true)\n",
      " |-- Mapped_Search_Term: string (nullable = true)\n",
      " |-- Mapped_Product_Collection: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos lo datos en Train, Validation y Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation, test  = data.randomSplit([0.7, 0.2, 0.1], 1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construimos el Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [item[0] for item in data.dtypes if item[1].startswith('string')]\n",
    "numeric_columns = [item[0] for item in data.dtypes if item[1].startswith('double')]\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol='{0}_index'.format(column)) for column in categorical_columns]\n",
    "\n",
    "featuresCreator = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + numeric_columns, outputCol=\"features\")\n",
    "\n",
    "layers = [len(featuresCreator.getInputCols()), 4, 2, 2]\n",
    "\n",
    "classifier = MultilayerPerceptronClassifier(labelCol='label', featuresCol='features', maxIter=1000, layers=layers, blockSize=1024, seed=1234)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [featuresCreator, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validamos y Evaluamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_df = model.transform(train)\n",
    "validation_output_df = model.transform(validation)\n",
    "test_output_df = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevamos a cabo, algunas predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train weightedPrecision = 0.9737665435248012\n",
      "Validation weightedPrecision = 0.9746155843208265\n",
      "Test weightedPrecision = 0.9782946313349752\n",
      "Train weightedRecall = 0.9729656032098477\n",
      "Validation weightedRecall = 0.9738482384823848\n",
      "Test weightedRecall = 0.9776574136763709\n",
      "Train accuracy = 0.9729656032098477\n",
      "Validation accuracy = 0.9738482384823848\n",
      "Test accuracy = 0.977657413676371\n"
     ]
    }
   ],
   "source": [
    "train_predictionAndLabels = train_output_df.select(\"prediction\", \"label\")\n",
    "validation_predictionAndLabels = validation_output_df.select(\"prediction\", \"label\")\n",
    "test_predictionAndLabels = test_output_df.select(\"prediction\", \"label\")\n",
    "\n",
    "metrics = ['weightedPrecision', 'weightedRecall', 'accuracy']\n",
    "\n",
    "for metric in metrics:\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName=metric)\n",
    "    print('Train ' + metric + ' = ' + str(evaluator.evaluate(train_predictionAndLabels)))\n",
    "    print('Validation ' + metric + ' = ' + str(evaluator.evaluate(validation_predictionAndLabels)))\n",
    "    print('Test ' + metric + ' = ' + str(evaluator.evaluate(test_predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede mejorar el test accuracy del modelo variando alguno de los hyperparametros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Respuesta:\n",
    " S칤 puede mejorarse, algunos resultados cambiando maxIter y blockSize:\n",
    " \n",
    " maxIter=100, layers=layers, blockSize=128, seed=1234\n",
    " Accuracy = 0.9729\n",
    " \n",
    " maxIter=200, layers=layers, blockSize=256, seed=1234\n",
    " Accuracy = 0.9737\n",
    " \n",
    " maxIter=400, layers=layers, blockSize=512, seed=1234\n",
    " Accuracy = 0.9779  <--- este fue el mayor valor obtenido con las pruebas realizadas\n",
    " \n",
    " maxIter=1000, layers=layers, blockSize=1024, seed=1234\n",
    " Accuracy = 0.9776\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
